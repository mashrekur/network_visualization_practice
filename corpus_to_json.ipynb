{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd \n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTopics = 25\n",
    "\n",
    "# Load model\n",
    "lda_model = LdaModel.load(f'trained_models/trained_lda_model_{nTopics}')\n",
    "\n",
    "# Load topic distributions\n",
    "topic_distributions = np.load(f'data/topic_distributions_{lda_model.num_topics}.npy')\n",
    "\n",
    "# Pull topics\n",
    "topics = lda_model.show_topics(formatted=False, num_topics=nTopics, num_words=20)\n",
    "\n",
    "# load raw corpus dataframe\n",
    "with open('data/raw_corpus.pkl', 'rb') as f:\n",
    "    corpus_df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define topic names\n",
    "topic_names = [\n",
    "    'Precip Variability & Extr',\n",
    "    'Hydrogeochemistry',\n",
    "    'Uncertainty',\n",
    "    'Soil Moisture',\n",
    "    'Statistical Hydrology',\n",
    "    'Rainfall-Runoff',\n",
    "    'Precip Observation',\n",
    "    'Modeling & Calibration',\n",
    "    'Water Management',\n",
    "    'Snow Hydrology',\n",
    "    'Streamflow Processes',\n",
    "    'Water Quality',\n",
    "    'Channel Flow',\n",
    "    'Floods',\n",
    "    'Sediment & Erosion',\n",
    "    'Climate Change',\n",
    "    'Subsurface Flow & Trans',\n",
    "    'Scaling & Spatial Variabil',\n",
    "    'Land Surface Fluxes',\n",
    "    'Hydrogeology',\n",
    "    'Human Interv & Eff',\n",
    "    'Land Cover',\n",
    "    'Systems Hydrology',\n",
    "    'Modeling & Forecasting',\n",
    "    'Groundwater'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors to associate with each topic\n",
    "custom_colors = {\n",
    " 'burlywood': '#DEB887',\n",
    " 'chocolate': '#D2691E',\n",
    " 'crimson': '#DC143C',\n",
    " 'darkgreen': '#006400',\n",
    " 'darkorange': '#FF8C00',\n",
    " 'darkslategrey': '#2F4F4F',\n",
    " 'deepskyblue': '#00BFFF',\n",
    " 'dimgray': '#696969',\n",
    " 'firebrick': '#B22222',\n",
    " 'gold': '#FFD700',\n",
    " 'goldenrod': '#DAA520',\n",
    " 'lawngreen': '#7CFC00',\n",
    " 'lightcoral': '#F08080',\n",
    " 'lightpink': '#FFB6C1',\n",
    " 'mediumvioletred': '#C71585',\n",
    " 'orangered': '#FF4500',\n",
    " 'orchid': '#DA70D6',\n",
    " 'royalblue': '#4169E1',\n",
    " 'slateblue': '#6A5ACD',\n",
    " 'springgreen': '#00FF7F',\n",
    " 'steelblue': '#4682B4',\n",
    " 'teal': '#008080',\n",
    " 'turquoise': '#40E0D0',\n",
    " 'yellow': '#FFFF00',\n",
    " 'blueviolet': '#8A2BE2',\n",
    " 'yellowgreen': '#9ACD32'}\n",
    "\n",
    "# turn into a list\n",
    "colorlist = []\n",
    "for i, color in enumerate(custom_colors.values()):\n",
    "    colorlist.append(tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)))\n",
    "    colorlist[i] = (colorlist[i][0] / 256, colorlist[i][1] / 256, colorlist[i][2] / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate individual lists for nodes and links\n",
    "node_list = []\n",
    "link_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe for link_list where\n",
    "#cols: [number, source, target, value]\n",
    "#number = number\n",
    "#source and target are paper ids in pairs\n",
    "#value = 1/JSD?\n",
    "#group = topics\n",
    "\n",
    "#create another dataframe for node_list, where\n",
    "#cols : [group, name]\n",
    "#group = topics\n",
    "#name = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate JSD for all pairs of papers\n",
    "def calc_KL_divergence(p1,p2):\n",
    "    return -np.nansum(p1 * np.log(p2/p1))\n",
    "def jensen_shannon_distance(p1,p2):\n",
    "    M=0.5*(p1+p2)\n",
    "    D1=calc_KL_divergence(p1,M)\n",
    "    D2=calc_KL_divergence(p2,M)\n",
    "    JSDiv = 0.5*D1+0.5*D2\n",
    "    JSD = np.sqrt(JSDiv)\n",
    "    return JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1, paper1 in enumerate(corpus):\n",
    "    record = {\"name\": paper1, \"group\": np.argmax(topic_distributions[paper1, :])}\n",
    "    nodes_list.append(record)\n",
    "    for p2,paper2 in enumerate(corpus):\n",
    "        distance = 1/JSD(paper1,paper2)\n",
    "        record = {\"value\": distance, \"source\": paper1, \"target\": paper2}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
