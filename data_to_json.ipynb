{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd \n",
    "from gensim.models import LdaModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTopics = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lda_model = LdaModel.load(f'trained_models/trained_lda_model_{nTopics}')\n",
    "\n",
    "# Load topic distributions\n",
    "topic_distributions = np.load(f'data/topic_distributions_{lda_model.num_topics}.npy')\n",
    "\n",
    "# Pull topics\n",
    "topics = lda_model.show_topics(formatted=False, num_topics=nTopics, num_words=20)\n",
    "\n",
    "# load raw corpus dataframe\n",
    "with open('data/raw_corpus.pkl', 'rb') as f:\n",
    "    corpus_df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all nans to zeros and all zeros to a very small number\n",
    "# topic_distributions = np.nan_to_num(topic_distributions)\n",
    "topic_distributions = np.where(topic_distributions == 0, 0.000001, topic_distributions)\n",
    "# topic_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(topic_distributions == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define topic names\n",
    "# topic_names = [\n",
    "#     'Precip Variability & Extr',\n",
    "#     'Hydrogeochemistry',\n",
    "#     'Uncertainty',\n",
    "#     'Soil Moisture',\n",
    "#     'Statistical Hydrology',\n",
    "#     'Rainfall-Runoff',\n",
    "#     'Precip Observation',\n",
    "#     'Modeling & Calibration',\n",
    "#     'Water Management',\n",
    "#     'Snow Hydrology',\n",
    "#     'Streamflow Processes',\n",
    "#     'Water Quality',\n",
    "#     'Channel Flow',\n",
    "#     'Floods',\n",
    "#     'Sediment & Erosion',\n",
    "#     'Climate Change',\n",
    "#     'Subsurface Flow & Trans',\n",
    "#     'Scaling & Spatial Variabil',\n",
    "#     'Land Surface Fluxes',\n",
    "#     'Hydrogeology',\n",
    "#     'Human Interv & Eff',\n",
    "#     'Land Cover',\n",
    "#     'Systems Hydrology',\n",
    "#     'Modeling & Forecasting',\n",
    "#     'Groundwater'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define colors to associate with each topic\n",
    "# custom_colors = {\n",
    "#  'burlywood': '#DEB887',\n",
    "#  'chocolate': '#D2691E',\n",
    "#  'crimson': '#DC143C',\n",
    "#  'darkgreen': '#006400',\n",
    "#  'darkorange': '#FF8C00',\n",
    "#  'darkslategrey': '#2F4F4F',\n",
    "#  'deepskyblue': '#00BFFF',\n",
    "#  'dimgray': '#696969',\n",
    "#  'firebrick': '#B22222',\n",
    "#  'gold': '#FFD700',\n",
    "#  'goldenrod': '#DAA520',\n",
    "#  'lawngreen': '#7CFC00',\n",
    "#  'lightcoral': '#F08080',\n",
    "#  'lightpink': '#FFB6C1',\n",
    "#  'mediumvioletred': '#C71585',\n",
    "#  'orangered': '#FF4500',\n",
    "#  'orchid': '#DA70D6',\n",
    "#  'royalblue': '#4169E1',\n",
    "#  'slateblue': '#6A5ACD',\n",
    "#  'springgreen': '#00FF7F',\n",
    "#  'steelblue': '#4682B4',\n",
    "#  'teal': '#008080',\n",
    "#  'turquoise': '#40E0D0',\n",
    "#  'yellow': '#FFFF00',\n",
    "#  'blueviolet': '#8A2BE2',\n",
    "#  'yellowgreen': '#9ACD32'}\n",
    "\n",
    "# # turn into a list\n",
    "# colorlist = []\n",
    "# for i, color in enumerate(custom_colors.values()):\n",
    "#     colorlist.append(tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)))\n",
    "#     colorlist[i] = (colorlist[i][0] / 256, colorlist[i][1] / 256, colorlist[i][2] / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note to self:\n",
    "# Redo using LDA mallet posterior distributions\n",
    "# Remove NaNs from dataframe\n",
    "# Create numpy arrays based on topics and store them\n",
    "# Add radio buttons\n",
    "# Think about better algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate JSD for all pairs of papers\n",
    "#the max force values (dist) are capped to 1000 later on\n",
    "def calc_KL_divergence(paper1,paper2):\n",
    "    return -np.nansum(paper1 * np.log(paper2/paper1))\n",
    "def jensen_shannon_distance(paper1,paper2):\n",
    "    M=0.5*(paper1+paper2)\n",
    "    D1=calc_KL_divergence(paper1,M)\n",
    "    D2=calc_KL_divergence(paper2,M)\n",
    "    JSDiv = 0.5*D1+0.5*D2\n",
    "    JSD = np.sqrt(JSDiv)\n",
    "    return JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert year of publication: 2018\n",
      "Insert journal id (options: WRR, HESS, JHM, HSJ, JH, HP): WRR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38685</th>\n",
       "      <td>10.1029/2017WR022499</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>The HydroGrid as a Framework for Interconnecte...</td>\n",
       "      <td>This paper introduces the concept of the Hydro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38686</th>\n",
       "      <td>10.1029/2017WR022437</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Satellite Remote Sensing for Water Resources M...</td>\n",
       "      <td>Water resources management (WRM) for sustainab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38687</th>\n",
       "      <td>10.1029/2018WR022819</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Finite Amplitude of Free Alternate Bars With S...</td>\n",
       "      <td>River bars are macroscale sediment patterns, w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38688</th>\n",
       "      <td>10.1029/2018WR023539</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>A High-Resolution Global Map of Soil Hydraulic...</td>\n",
       "      <td>A correct quantification of mass and energy ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38689</th>\n",
       "      <td>10.1029/2017WR021837</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>An Empirical Examination on the Role of Water ...</td>\n",
       "      <td>Water user associations (WUAs) are commonly co...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39251</th>\n",
       "      <td>10.1002/2017WR021648</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Modeling of Future Changes in Seasonal Snowpac...</td>\n",
       "      <td>It is expected that an increasing proportion o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39252</th>\n",
       "      <td>10.1002/2017WR021806</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Unraveling the Hydrology of the Glacierized Ka...</td>\n",
       "      <td>Understanding the water balance, especially as...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39253</th>\n",
       "      <td>10.1002/2017WR021391</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Analytical Solution for Interface Flow to a Si...</td>\n",
       "      <td>A study is made of a steady, two-dimensional g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39254</th>\n",
       "      <td>10.1002/2017WR021563</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Comment on ``An Efficient and Stable Hydrodyna...</td>\n",
       "      <td>Xia et al. (2017) proposed a novel, fully impl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39255</th>\n",
       "      <td>10.1002/2017WR021696</td>\n",
       "      <td>2018</td>\n",
       "      <td>WRR</td>\n",
       "      <td>Reply to Comment by Lu et al. on ``An Efficien...</td>\n",
       "      <td>This document addresses the comments raised by...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DOI  Year Journal  \\\n",
       "38685  10.1029/2017WR022499  2018     WRR   \n",
       "38686  10.1029/2017WR022437  2018     WRR   \n",
       "38687  10.1029/2018WR022819  2018     WRR   \n",
       "38688  10.1029/2018WR023539  2018     WRR   \n",
       "38689  10.1029/2017WR021837  2018     WRR   \n",
       "...                     ...   ...     ...   \n",
       "39251  10.1002/2017WR021648  2018     WRR   \n",
       "39252  10.1002/2017WR021806  2018     WRR   \n",
       "39253  10.1002/2017WR021391  2018     WRR   \n",
       "39254  10.1002/2017WR021563  2018     WRR   \n",
       "39255  10.1002/2017WR021696  2018     WRR   \n",
       "\n",
       "                                                   Title  \\\n",
       "38685  The HydroGrid as a Framework for Interconnecte...   \n",
       "38686  Satellite Remote Sensing for Water Resources M...   \n",
       "38687  Finite Amplitude of Free Alternate Bars With S...   \n",
       "38688  A High-Resolution Global Map of Soil Hydraulic...   \n",
       "38689  An Empirical Examination on the Role of Water ...   \n",
       "...                                                  ...   \n",
       "39251  Modeling of Future Changes in Seasonal Snowpac...   \n",
       "39252  Unraveling the Hydrology of the Glacierized Ka...   \n",
       "39253  Analytical Solution for Interface Flow to a Si...   \n",
       "39254  Comment on ``An Efficient and Stable Hydrodyna...   \n",
       "39255  Reply to Comment by Lu et al. on ``An Efficien...   \n",
       "\n",
       "                                                Abstract Affiliation  \n",
       "38685  This paper introduces the concept of the Hydro...         NaN  \n",
       "38686  Water resources management (WRM) for sustainab...         NaN  \n",
       "38687  River bars are macroscale sediment patterns, w...         NaN  \n",
       "38688  A correct quantification of mass and energy ex...         NaN  \n",
       "38689  Water user associations (WUAs) are commonly co...         NaN  \n",
       "...                                                  ...         ...  \n",
       "39251  It is expected that an increasing proportion o...         NaN  \n",
       "39252  Understanding the water balance, especially as...         NaN  \n",
       "39253  A study is made of a steady, two-dimensional g...         NaN  \n",
       "39254  Xia et al. (2017) proposed a novel, fully impl...         NaN  \n",
       "39255  This document addresses the comments raised by...         NaN  \n",
       "\n",
       "[571 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select by year and journal\n",
    "year_id = input(\"Insert year of publication: \")\n",
    "journal_id = input(\"Insert journal id (options: WRR, HESS, JHM, HSJ, JH, HP): \")\n",
    "df_year = corpus_df.loc[corpus_df['Year'] == year_id]\n",
    "df_year_journal = df_year.loc[df_year['Journal'] == journal_id]\n",
    "df_year_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select minimum paper distance cutoff (Options: High, Medium, Low): Medium\n",
      "Select topic; refer to the list of topics below and choose your number(for all topics, input 'all') all\n"
     ]
    }
   ],
   "source": [
    "#Select minimum paper correlation cutoff point (use quantiles instead)\n",
    "min_cutoff = input(\"Select minimum paper distance cutoff (Options: High, Medium, Low): \")\n",
    "min_cutoff = min_cutoff.lower()\n",
    "\n",
    "#Note to self - set quantiles\n",
    "if min_cutoff == 'high':\n",
    "    cut_val = 2.5\n",
    "elif min_cutoff == 'medium':\n",
    "    cut_val = 2.0\n",
    "elif min_cutoff == 'low':\n",
    "    cut_val == 1.5   \n",
    "\n",
    "\n",
    "#select topic\n",
    "sel_topic = input(\"Select topic; refer to the list of topics below and choose your number(for all topics, input 'all') \")\n",
    "# '0'     'Precip Variability & Extr',\n",
    "# '1'     'Hydrogeochemistry',\n",
    "# '2'     'Uncertainty',\n",
    "# '3'    'Soil Moisture',\n",
    "# '4'    'Statistical Hydrology',\n",
    "# '5'    'Rainfall-Runoff',\n",
    "# '6'    'Precip Observation',\n",
    "# '7'    'Modeling & Calibration',\n",
    "# '8'    'Water Management',\n",
    "# '9'    'Snow Hydrology',\n",
    "# '10'    'Streamflow Processes',\n",
    "# '11'   'Water Quality',\n",
    "# '12'     'Channel Flow',\n",
    "# '13'     'Floods',\n",
    "# '14'     'Sediment & Erosion',\n",
    "# '15'     'Climate Change',\n",
    "# '16'     'Subsurface Flow & Trans',\n",
    "# '17'     'Scaling & Spatial Variabil',\n",
    "# '18'     'Land Surface Fluxes',\n",
    "# '19'     'Hydrogeology',\n",
    "# '20'     'Human Interv & Eff',\n",
    "# '21'     'Land Cover',\n",
    "# '22'     'Systems Hydrology',\n",
    "# '23'     'Modeling & Forecasting',\n",
    "# '24'     'Groundwater'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsd_np_array[jsd_np_array =< cutoff_value] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #initiate individual lists for nodes and links\n",
    "# node_list = []\n",
    "# link_list = []\n",
    "\n",
    "# # dist_values = np.full([corpus_df.shape[0], corpus_df.shape[0]], np.nan)\n",
    "# # dist_values = np.full([1000, 1000], -0.1)\n",
    "    \n",
    "# for p1, paper1 in enumerate(df_year_journal[\"Title\"][:]):\n",
    "#     max_topic = np.argmax(topic_distributions[p1])\n",
    "#     grp = {\"group\" : max_topic, \"name\": paper1}\n",
    "#     node_list.append(grp)\n",
    "#     for p2, paper2 in enumerate(df_year_journal[\"Title\"][p1:]):\n",
    "#         if p1 == p2:\n",
    "#             dist = 0\n",
    "#         else:\n",
    "#             #round to 2 decimal places\n",
    "#             if sel_topic == 'all':\n",
    "#                 JSD = jensen_shannon_distance(topic_distributions[p1, :], topic_distributions[p2, :])\n",
    "#             else:\n",
    "#                 JSD = jensen_shannon_distance(topic_distributions[p1, sel_topic], topic_distributions[p2, sel_topic])\n",
    "#             dist = round(1/JSD, 2)\n",
    "#             if dist >= cut_val and dist <= 10:\n",
    "#                 link = {\"source\": p1, \"target\": p2, \"value\": dist}\n",
    "#                 link_list.append(link)\n",
    "#             continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose first topic: 10\n",
      "Choose second topic: 15\n"
     ]
    }
   ],
   "source": [
    "#choose topic pairs\n",
    "k1 = input(\"Choose first topic: \")\n",
    "k2 = input(\"Choose second topic: \")\n",
    "\n",
    "node_list = []\n",
    "#returning indices of maximum topic distributions for pairs of topics\n",
    "# for i in range(0,42154,1):\n",
    "#     mx = np.argmax(topic_distributions[:][i])\n",
    "#     if mx == 10:\n",
    "#         print(mx)\n",
    "for p1, paper1 in enumerate(df_year_journal[\"Title\"][:]):\n",
    "    max_topic = np.argmax(topic_distributions[p1])\n",
    "    grp = {\"group\" : max_topic, \"name\": paper1}\n",
    "    if max_topic == k1 and max_topic == k2:\n",
    "        node_list.append(grp)\n",
    "        continue\n",
    "#     for p2, paper2 in enumerate(df_year_journal[\"Title\"][p1:]):\n",
    "#         if p1 == p2:\n",
    "#             dist = 0\n",
    "#         else:\n",
    "#             JSD = jensen_shannon_distance(topic_distributions[p1, k1], topic_distributions[p2, sel_topic])\n",
    "#             dist = round(1/JSD, 2)\n",
    "#             if dist >= cut_val and dist <= 10:\n",
    "#                 link = {\"source\": p1, \"target\": p2, \"value\": dist}\n",
    "#                 link_list.append(link)\n",
    "#             continue\n",
    "#     print(grp)\n",
    "#     else:\n",
    "#         continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy arrays and save them\n",
    "link_arr = np.array(link_list)\n",
    "np.save('link_array', link_arr, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "\n",
    "node_arr = np.array(node_list)\n",
    "np.save('node_array', node_arr, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the lists\n",
    "# with open(\"node_list_full20.txt\", \"wb\") as fp:\n",
    "#     pkl.dump(node_list, fp)\n",
    "# with open(\"link_list_full20.txt\", \"wb\") as fp:\n",
    "#     pkl.dump(link_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate json file\n",
    "json_prep = {\"links\":link_list, \"nodes\":node_list}\n",
    "# json_prep = {\"links\":link_list}\n",
    "#json does not recognize NumPy data types; defining own encoder\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "#dumping the data into json file\n",
    "json_dump = json.dumps(json_prep, indent=1, sort_keys=True, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(json_prep['nodes']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(json_prep['links']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output\n",
    "filename_out = 'hiddenstories_year_journal.json'\n",
    "json_out = open(filename_out,'w')\n",
    "json_out.write(json_dump)\n",
    "json_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
